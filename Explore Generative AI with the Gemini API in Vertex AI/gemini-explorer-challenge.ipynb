{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc61ef2",
   "metadata": {},
   "source": [
    "### Getting Started "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5040b",
   "metadata": {},
   "source": [
    "#### Install Google Gen AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0cb94a-444f-4360-9196-395da2f58a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:36:57.994875Z",
     "iopub.status.busy": "2025-11-12T07:36:57.994345Z",
     "iopub.status.idle": "2025-11-12T07:37:00.222279Z",
     "shell.execute_reply": "2025-11-12T07:37:00.219392Z",
     "shell.execute_reply.started": "2025-11-12T07:36:57.994822Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a8346",
   "metadata": {},
   "source": [
    "#### Restart runtime\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58aad280-7db1-4e39-886b-336d7e5791d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:37:00.227107Z",
     "iopub.status.busy": "2025-11-12T07:37:00.226502Z",
     "iopub.status.idle": "2025-11-12T07:37:00.243642Z",
     "shell.execute_reply": "2025-11-12T07:37:00.242201Z",
     "shell.execute_reply.started": "2025-11-12T07:37:00.227047Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f5a9c",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45472ded-bc1f-47a5-9782-fb8fb8538f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:37:15.710169Z",
     "iopub.status.busy": "2025-11-12T07:37:15.709733Z",
     "iopub.status.idle": "2025-11-12T07:37:16.940559Z",
     "shell.execute_reply": "2025-11-12T07:37:16.938913Z",
     "shell.execute_reply.started": "2025-11-12T07:37:15.710118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Define project information\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-629a6ca913e4\"  # @param {type:\"string\"}\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")\n",
    "\n",
    "# Create the API client\n",
    "from google import genai\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d907146",
   "metadata": {},
   "source": [
    "#### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c672ce5-01ee-4884-a76f-c069d06c412a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:37:18.351937Z",
     "iopub.status.busy": "2025-11-12T07:37:18.351152Z",
     "iopub.status.idle": "2025-11-12T07:37:18.361416Z",
     "shell.execute_reply": "2025-11-12T07:37:18.358564Z",
     "shell.execute_reply.started": "2025-11-12T07:37:18.351889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    Tool,\n",
    "    Part\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc901e8a",
   "metadata": {},
   "source": [
    "### Task 3. Create a function call using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb0e9207-2646-4378-9350-cef083822807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:45:13.611169Z",
     "iopub.status.busy": "2025-11-12T07:45:13.610681Z",
     "iopub.status.idle": "2025-11-12T07:45:13.617993Z",
     "shell.execute_reply": "2025-11-12T07:45:13.615453Z",
     "shell.execute_reply.started": "2025-11-12T07:45:13.611130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.1\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "# Load Gemini 2.5 Flash Model\n",
    "model_id = (\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d349748-4a56-4759-98d7-e918b476c317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:45:17.037497Z",
     "iopub.status.busy": "2025-11-12T07:45:17.037067Z",
     "iopub.status.idle": "2025-11-12T07:45:17.044579Z",
     "shell.execute_reply": "2025-11-12T07:45:17.042224Z",
     "shell.execute_reply.started": "2025-11-12T07:45:17.037460Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.2\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"Get the current weather in a given location\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280aa0f9-ef27-4664-b9f6-ed6847d8f76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:45:20.417064Z",
     "iopub.status.busy": "2025-11-12T07:45:20.416655Z",
     "iopub.status.idle": "2025-11-12T07:45:20.423777Z",
     "shell.execute_reply": "2025-11-12T07:45:20.421552Z",
     "shell.execute_reply.started": "2025-11-12T07:45:20.417029Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 3.3\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "weather_tool = Tool(\n",
    "    function_declarations=[get_current_weather_func],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10b41dfd-5d43-4c21-8992-c76ed319af66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:45:22.808646Z",
     "iopub.status.busy": "2025-11-12T07:45:22.808200Z",
     "iopub.status.idle": "2025-11-12T07:45:23.492299Z",
     "shell.execute_reply": "2025-11-12T07:45:23.490873Z",
     "shell.execute_reply.started": "2025-11-12T07:45:22.808608Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-0.43562361172267366,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            function_call=FunctionCall(\n",
       "              args=<... Max depth ...>,\n",
       "              name=<... Max depth ...>\n",
       "            ),\n",
       "            thought_signature=b\"\\n\\xcb\\x01\\x01\\xe3\\xf1\\xff^$ Z\\x93\\xef\\xe8zi\\x11l\\xb8\\x97\\x8b:R\\xcbPk\\xee\\xb1\\xfbX\\xc8@4\\xb5\\xe9\\x8ac\\xa5O\\x96u/\\xe20\\xf3\\xa2\\x80;\\x994\\xfe-{\\x8c\\xcf\\xef[\\xbb\\xe7ef\\xcd[\\xfa\\x17[\\xe1\\xee?\\x94\\x7f\\xc7x`\\x08\\xc4\\xd8_'b5*?}l\\xb7\\x8f\\xdd\\xbd\\xd9\\n\\xe9\\xab\\xc1o\\x0c\\x87...'\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 11, 12, 7, 45, 22, 871111, tzinfo=TzInfo(0)),\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='EjsUaceVNeKCqsMPwbaR2AE',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=7,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=7\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=25,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=25\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=41,\n",
       "    total_token_count=73,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3.4\n",
    "# use the following documentation to assist you complete this cell\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling\n",
    "prompt = \"What is the weather like in Boston?\"\n",
    "response = client.models.generate_content(\n",
    "    model=model_id,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[weather_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de586d1d",
   "metadata": {},
   "source": [
    "### Task 4. Describe video contents using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e8033df-507a-4fc8-b14c-f015be9f66af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:40:04.178217Z",
     "iopub.status.busy": "2025-11-12T07:40:04.177551Z",
     "iopub.status.idle": "2025-11-12T07:40:04.191141Z",
     "shell.execute_reply": "2025-11-12T07:40:04.189923Z",
     "shell.execute_reply.started": "2025-11-12T07:40:04.178164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the following cell to import required libraries \n",
    "from google.genai.types import (\n",
    "    GenerationConfig,\n",
    "    Image,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75434b8d-e7d0-4241-9cab-fa735a617b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:40:06.185040Z",
     "iopub.status.busy": "2025-11-12T07:40:06.184573Z",
     "iopub.status.idle": "2025-11-12T07:40:06.191116Z",
     "shell.execute_reply": "2025-11-12T07:40:06.189560Z",
     "shell.execute_reply.started": "2025-11-12T07:40:06.185001Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Task 4.1\n",
    "# Load the correct Gemini model use the following documentation to assist:\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview#supported-use-cases\n",
    "# Load Gemini 2.5 Flash Model\n",
    "multimodal_model = (\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b6f262-1956-4c3e-a0ab-39b412d19ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:40:19.294743Z",
     "iopub.status.busy": "2025-11-12T07:40:19.294308Z",
     "iopub.status.idle": "2025-11-12T07:40:19.311480Z",
     "shell.execute_reply": "2025-11-12T07:40:19.309573Z",
     "shell.execute_reply.started": "2025-11-12T07:40:19.294704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "        return False\n",
    "    display_images([content])\n",
    "    return True\n",
    "\n",
    "\n",
    "def display_content_as_video(content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "        return False\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix(\"gs://\")\n",
    "    video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "    return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list[str | Image | Part]):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if display_content_as_image(content):\n",
    "            continue\n",
    "        if display_content_as_video(content):\n",
    "            continue\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17aae9ba-edcb-4c63-af88-26380dfd5170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T07:42:55.676573Z",
     "iopub.status.busy": "2025-11-12T07:42:55.676062Z",
     "iopub.status.idle": "2025-11-12T07:43:11.133228Z",
     "shell.execute_reply": "2025-11-12T07:43:11.131968Z",
     "shell.execute_reply.started": "2025-11-12T07:42:55.676523Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Prompt--------\n",
      "\n",
      "What is shown in this video?\n",
      "Where should I go to see it?\n",
      "What are the top 5 places in the world that look like this?\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\" controls  width=\"600\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------Response--------\n",
      "This video shows an aerial view of a vibrant **coastal city with a historical harbor nestled against dramatic cliffs**. The turquoise-blue sea is visible, with waves crashing against a stone breakwater that features a lighthouse. Inside the sheltered harbor, numerous boats, including yachts and what appears to be a tour boat, are docked. White and light-colored buildings of the city are spread across the high cliffs overlooking the sea.\n",
      "\n",
      "You should go to **Antalya, Turkey** to see this specific location. This is the **Old Harbor (Kalei√ßi Marina)** in Antalya, famous for its picturesque setting with the Taurus Mountains in the distance (though not clearly visible in this specific frame) and the city built along the towering cliffs known as the \"Falezler.\"\n",
      "\n",
      "Based on the combination of a coastal city built on cliffs, featuring a harbor or marina, and beautiful clear waters, here are 5 places in the world that look similar or offer a comparable experience:\n",
      "\n",
      "1.  **Santorini, Greece:** Famous for its iconic white-washed villages (like Oia and Fira) perched on the cliffs of a volcanic caldera, overlooking the Aegean Sea.\n",
      "2.  **Amalfi Coast, Italy:** Towns like Positano and Amalfi are built dramatically into steep cliffs, featuring colorful houses, charming harbors, and stunning views of the Mediterranean.\n",
      "3.  **Dubrovnik, Croatia:** The \"Pearl of the Adriatic\" is a walled city built on rocky cliffs overlooking the clear blue Adriatic Sea, with a beautiful old harbor.\n",
      "4.  **Cinque Terre, Italy:** A string of five colorful fishing villages clinging to the rugged coastline and cliffs of the Italian Riviera, with small harbors and terraced vineyards.\n",
      "5.  **Lisbon, Portugal:** While not directly on cliffs in the same way, Lisbon is built on seven hills overlooking the Tagus River estuary and the Atlantic Ocean, offering dramatic panoramic views, historic districts, and a strong maritime feel."
     ]
    }
   ],
   "source": [
    "# Task 4.2 Generate a video description\n",
    "# In this cell, update the prompt to ask Gemini to describe the video URL referenced.\n",
    "# You can use the documentation at the following link to assist.\n",
    "# https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference#generate-content-from-video\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#sample-requests-text-stream-response\n",
    "# Video URI: gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\n",
    "\n",
    "prompt = \"\"\"\n",
    "What is shown in this video?\n",
    "Where should I go to see it?\n",
    "What are the top 5 places in the world that look like this?\n",
    "\"\"\"\n",
    "video = Part.from_uri(\n",
    "    file_uri=\"gs://github-repo/img/gemini/multimodality_usecases_overview/mediterraneansea.mp4\",\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "responses = client.models.generate_content_stream(\n",
    "    model=multimodal_model,\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f07101-43fb-45ba-a844-3918768d99bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m135",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m135"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
